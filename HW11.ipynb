{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7266df9",
   "metadata": {},
   "source": [
    "Q2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a3ec84",
   "metadata": {},
   "source": [
    "1. Accuracy: Best used when false positives and false negatives have comparable consequences, and the class distribution is balanced.\n",
    "Example (Weather Prediction): Predicting if it will rain tomorrow (yes/no) in a region where rain occurs about 50% of the time. Since false alarms and missed rain predictions have similar effects, accuracy serves as a suitable metric.\n",
    "\n",
    "2. Sensitivity (Recall): Focuses on identifying the proportion of actual positives that are correctly detected.\n",
    "Example (Medical Diagnosis): Screening for cancer in patients. A missed cancer diagnosis (false negative) is far more serious than a false alarm (false positive). High sensitivity ensures most cancer cases are identified.\n",
    "\n",
    "3. Specificity: Emphasizes the proportion of actual negatives correctly identified.\n",
    "Example (Spam Filtering): Preventing legitimate emails from being marked as spam. Here, false positives (valid emails flagged as spam) are more problematic than missing a few spam emails, making high specificity crucial.\n",
    "\n",
    "4. Precision: Evaluates the proportion of predicted positives that are true positives.\n",
    "Example (Fraud Detection): Flagging fraudulent transactions in financial systems. False positives (legitimate transactions flagged as fraud) can cause customer dissatisfaction and operational challenges. High precision minimizes unnecessary alerts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6ce575",
   "metadata": {},
   "source": [
    "Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89aadb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "ab_reduced_noNaN_train, ab_reduced_noNaN_test = train_test_split(ab_reduced_noNaN, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reporting the number of observations in each set\n",
    "print(\"Number of observations in the training set:\", len(ab_reduced_noNaN_train))\n",
    "print(\"Number of observations in the test set:\", len(ab_reduced_noNaN_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43abe5d",
   "metadata": {},
   "source": [
    "y = pd.get_dummies(ab_reduced_noNaN[\"Hard_or_Paper\"])['H']: This applies one-hot encoding to the categorical variable Hard_or_Paper, converting it into a binary format. The resulting variable, y, is set to 1 for \"Hardcover\" ('H') and 0 for all other categories.\n",
    "\n",
    "X = ab_reduced_noNaN[['List Price']]: This extracts the List Price column from the dataset, creating a DataFrame X to be used as the input feature for model training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6e34dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Preparing the data for training\n",
    "y = pd.get_dummies(ab_reduced_noNaN[\"Hard_or_Paper\"])['H']\n",
    "X = ab_reduced_noNaN[['List Price']]\n",
    "\n",
    "# Initializing and training the DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Visualizing the tree\n",
    "plt.figure(figsize=(10, 6))\n",
    "tree.plot_tree(clf, feature_names=['List Price'], class_names=['Paper', 'Hard'], filled=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50014ff",
   "metadata": {},
   "source": [
    "Train-Test Split:\n",
    "\n",
    "Discussed how to divide a dataset into training and testing sets using an 80/20 split via train_test_split.\n",
    "Provided code to create the training (ab_reduced_noNaN_train) and testing (ab_reduced_noNaN_test) datasets and to count the number of observations in each.\n",
    "Understanding Data Preparation:\n",
    "\n",
    "Explained the following steps:\n",
    "y = pd.get_dummies(ab_reduced_noNaN[\"Hard_or_Paper\"])['H']: Converts the categorical variable \"Hard_or_Paper\" into a binary format, with 1 for \"hardcover\" and 0 for \"paperback.\"\n",
    "X = ab_reduced_noNaN[['List Price']]: Extracts the \"List Price\" column to use as the feature for model training.\n",
    "Training a Decision Tree:\n",
    "\n",
    "Provided code to initialize and train a DecisionTreeClassifier (clf) using the \"List Price\" feature to predict the book format.\n",
    "Set the tree's maximum depth to 2 for simplicity.\n",
    "Visualizing the Decision Tree:\n",
    "\n",
    "Shared code to use tree.plot_tree for visualizing the decision-making process. This includes:\n",
    "Splits based on \"List Price\" thresholds.\n",
    "Class predictions at the terminal nodes.\n",
    "\n",
    "Interpreting the Decision Tree:\n",
    "Summarized how the tree uses splits in the \"List Price\" feature to predict whether a book is \"hardcover\" or \"paperback.\"\n",
    "Highlighted how terminal nodes indicate class probabilities and predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aced36c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca11cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining X and y\n",
    "X = ab_reduced_noNaN[['NumPages', 'Thick', 'List Price']]\n",
    "y = pd.get_dummies(ab_reduced_noNaN[\"Hard_or_Paper\"])['H']\n",
    "\n",
    "# Initialize and train the model\n",
    "clf2 = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
    "clf2.fit(X, y)\n",
    "\n",
    "# Simple tree visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "tree.plot_tree(clf2, feature_names=['NumPages', 'Thick', 'List Price'], class_names=['Paper', 'Hard'], filled=True)\n",
    "plt.show()\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {'max_depth': [2, 3, 4, 5, 6]}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best max_depth:\", grid_search.best_params_['max_depth'])\n",
    "print(\"Best accuracy:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aee76bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae907c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Prepare the test data\n",
    "y_actual = pd.get_dummies(ab_reduced_noNaN_test[\"Hard_or_Paper\"])['H']\n",
    "X_clf_test = ab_reduced_noNaN_test[['List Price']]\n",
    "X_clf2_test = ab_reduced_noNaN_test[['NumPages', 'Thick', 'List Price']]\n",
    "\n",
    "# Generate predictions for both models\n",
    "y_predicted_clf = clf.predict(X_clf_test)\n",
    "y_predicted_clf2 = clf2.predict(X_clf2_test)\n",
    "\n",
    "# Compute confusion matrices\n",
    "confusion_matrix_clf = confusion_matrix(y_actual, y_predicted_clf)\n",
    "confusion_matrix_clf2 = confusion_matrix(y_actual, y_predicted_clf2)\n",
    "\n",
    "# Define a function to calculate performance metrics\n",
    "def calculate_metrics(conf_matrix):\n",
    "    TP = conf_matrix[1, 1]\n",
    "    TN = conf_matrix[0, 0]\n",
    "    FP = conf_matrix[0, 1]\n",
    "    FN = conf_matrix[1, 0]\n",
    "\n",
    "    sensitivity = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    specificity = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "    accuracy = (TP + TN) / conf_matrix.sum()\n",
    "\n",
    "    return np.round([sensitivity, specificity, accuracy], 3)\n",
    "\n",
    "# Evaluate both models\n",
    "metrics_for_clf = calculate_metrics(confusion_matrix_clf)\n",
    "metrics_for_clf2 = calculate_metrics(confusion_matrix_clf2)\n",
    "\n",
    "# Display the results\n",
    "print(\"Confusion Matrix for clf:\\n\", confusion_matrix_clf)\n",
    "print(\"Sensitivity, Specificity, Accuracy for clf:\", metrics_for_clf)\n",
    "\n",
    "print(\"\\nConfusion Matrix for clf2:\\n\", confusion_matrix_clf2)\n",
    "print(\"Sensitivity, Specificity, Accuracy for clf2:\", metrics_for_clf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5e421c",
   "metadata": {},
   "source": [
    "Confusion Matrix and Metrics for Models:\n",
    "\n",
    "Confusion Matrix for clf:\n",
    " [[40  4]\n",
    " [ 3 17]]\n",
    "Sensitivity, Specificity, Accuracy:\n",
    "\n",
    "Sensitivity: 0.85\n",
    "Specificity: 0.909\n",
    "Accuracy: 0.891\n",
    "Confusion Matrix for clf2:\n",
    "[[42  2]\n",
    " [ 2 18]]\n",
    "Sensitivity, Specificity, Accuracy:\n",
    "\n",
    "Sensitivity: 0.9\n",
    "Specificity: 0.955\n",
    "Accuracy: 0.938\n",
    "Model Analysis:\n",
    "\n",
    "The confusion matrix provides the counts for True Positives (TP), True Negatives (TN), False Positives (FP), and False Negatives (FN).\n",
    "Sensitivity: Reflects the model's ability to correctly identify hardcover books.\n",
    "Specificity: Indicates how well the model identifies paperback books.\n",
    "Accuracy: Represents the overall performance of the model.\n",
    "Summary of Evaluation:\n",
    "\n",
    "Objective:\n",
    "Compare the performance of two classification models (clf and clf2) using confusion matrices and calculate key metrics.\n",
    "\n",
    "Key Concepts:\n",
    "\n",
    "Positive (P): Predicted hardcover (1).\n",
    "Negative (N): Predicted paperback (0).\n",
    "Confusion Matrix Terms:\n",
    "TP (True Positive): Correctly predicted hardcover books.\n",
    "TN (True Negative): Correctly predicted paperback books.\n",
    "FP (False Positive): Predicted hardcover, but the actual book is paperback.\n",
    "FN (False Negative): Predicted paperback, but the actual book is hardcover.\n",
    " \n",
    "Implementation:\n",
    "\n",
    "Used the test dataset (ab_reduced_noNaN_test) for predictions.\n",
    "Generated confusion matrices for clf and clf2.\n",
    "Calculated sensitivity, specificity, and accuracy using a helper function, rounding results to three decimal places.\n",
    "Results:\n",
    "\n",
    "Presented confusion matrices for both models.\n",
    "Reported sensitivity, specificity, and accuracy for each. Model clf2 demonstrates slightly better performance across all metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9ed90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb59dfd",
   "metadata": {},
   "source": [
    "The differences between the two confusion matrices arise from the features used by the models. The first model (clf) relies solely on a single feature, List Price, for its predictions. In contrast, the second model (clf2) utilizes three features—NumPages, Thick, and List Price. By leveraging a wider range of features, clf2 gains access to more information, enabling it to identify more complex patterns and improve its prediction accuracy. Both models were trained on a clean dataset without missing values, ensuring consistent and reliable results. The inclusion of additional features in clf2 results in fewer misclassifications, as evidenced by its superior performance in the confusion matrix."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
