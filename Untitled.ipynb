{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8423c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Summary of the Conversation:\n",
    "Dataset Overview: You asked about how to inspect the columns and size of a dataset using df.shape and df.describe(). We \n",
    "discussed that df.shape provides the dimensions (number of rows and columns), while df.describe() gives summary statistics \n",
    "like mean, min, max, and quartiles for numeric columns.\n",
    "\n",
    "Attributes vs Methods: We clarified the difference between an attribute and a method in pandas:\n",
    "\n",
    "Attribute: e.g., df.shape (no parentheses) gives information about the DataFrame without performing any action.\n",
    "Method: e.g., df.describe() (with parentheses) performs an operation and returns a result, in this case, summary statistics.\n",
    "Handling Missing Data: You wanted to know how to efficiently remove missing data:\n",
    "\n",
    "First, identify columns with many missing values and delete them using del df['col'].\n",
    "Then, use df.dropna() to remove rows with missing values, ensuring you retain useful data.\n",
    "We discussed the importance of deleting irrelevant columns before removing rows to avoid over-deleting data.\n",
    "Deleting Columns with Missing Data: I provided code for deleting specific columns with missing values:\n",
    "\n",
    "You can use df.isnull().sum() to find out how many missing values each column has.\n",
    "To remove columns with missing values using del df[], you can loop through those columns and delete them one by one.\n",
    "Runnable Code Example: We created a runnable code snippet that first identifies columns with missing values and then deletes\n",
    "those columns using del df[col]. This approach ensures that columns with missing values are efficiently removed without \n",
    "needing other functions like df.drop().\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8031be3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_n           0\n",
       "id              1\n",
       "name            0\n",
       "gender          0\n",
       "species         0\n",
       "birthday        0\n",
       "personality     0\n",
       "song           11\n",
       "phrase          0\n",
       "full_id         0\n",
       "url             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9b8a7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 391 rows and 11 columns.\n"
     ]
    }
   ],
   "source": [
    "rows, columns = df.shape\n",
    "\n",
    "# Print the result\n",
    "print(f\"The dataset has {rows} rows and {columns} columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b1e2fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>391.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>239.902813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>140.702672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>117.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>240.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>363.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>483.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_n\n",
       "count  391.000000\n",
       "mean   239.902813\n",
       "std    140.702672\n",
       "min      2.000000\n",
       "25%    117.500000\n",
       "50%    240.000000\n",
       "75%    363.500000\n",
       "max    483.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Statistical summary of numerical columns\n",
    "df.describe()\n",
    "\n",
    "# Display the first few rows to understand the data better\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eea782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' .shape gives the total number of rows and columns in the dataset, regardless of the type of data in those columns.\n",
    "    .describe() only provides statistical summaries for numeric columns. \n",
    "    .shape: The number of rows reported by shape includes all rows, regardless of whether they contain missing values or not. \n",
    "Even if a row has missing data in some numeric columns, it will still be counted as part of the total number of rows.\n",
    "    The count in describe() only refers to the non-null values\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609d900e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Attribute:\n",
    "Does not end with ()\n",
    "Returns a property or data\n",
    "Typically static information\n",
    "Accessed like a variable\n",
    "\n",
    "Method:\n",
    "Ends with ()\n",
    "Performs an action\n",
    "May involve computation or changes\n",
    "Called like a function   '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d062885",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "count: you how many valid entries exist for that particular column.\n",
    "mean: average of a group of values, calculated by adding value up and dividing by the number of terms\n",
    "std: The square root of the variance, where variance is the average of the squared differences from the mean.\n",
    "min: smallest term\n",
    "25%: First 25% of the data fell below this value\n",
    "50%: The middle value when arrange the data set in order\n",
    "75%: Last 25% of the data fell above this value\n",
    "max: The maximum value of this data set\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e338c5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['row_n', 'id', 'name', 'gender', 'species', 'birthday', 'personality',\n",
      "       'song', 'phrase', 'full_id', 'url'],\n",
      "      dtype='object')\n",
      "Columns with missing data:\n",
      "id       1\n",
      "song    11\n",
      "dtype: int64\n",
      "Columns after deletion:\n",
      "Index(['row_n', 'name', 'gender', 'species', 'birthday', 'personality',\n",
      "       'phrase', 'full_id', 'url'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "1. use when most missing datas are concentrated in a few rows, not when they are scattered aross different columns\n",
    "2. when most missing datas are in a few columns, removing a few row would remove most of missing data\n",
    "3. Losing a column of datas likely won't have significant effects of the data, as it represent one characteristic of the datas,\n",
    "   however, losing a row means losing an individual and could potentially decrease the reliability of the data set (decrease in n)\n",
    "   \n",
    "4. Identify Columns with Significant Missing Data\n",
    "   Remove Columns with High Missing Values\n",
    "   Remove Rows with Remaining Missing Values\n",
    "   \n",
    "'''\n",
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# before\n",
    "missing_values = df.isnull().sum()\n",
    "print(df.columns)\n",
    "print(\"Columns with missing data:\")\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "columns_with_missing_data = missing_values[missing_values > 0].index\n",
    "\n",
    "for col in columns_with_missing_data:\n",
    "    del df[col]\n",
    "    \n",
    "print(\"Columns after deletion:\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cd911fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'survived' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(url)\n\u001b[0;32m----> 9\u001b[0m DEADvsNOTDEAD \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[43msurvived\u001b[49m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(DEADvsNOTDEAD)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'survived' is not defined"
     ]
    }
   ],
   "source": [
    "'''The first part ''df.groupby(\"col1\")'' groups the DataFrame by every unique values in column 1, it creates many subsets each\n",
    "representing the datas following a specfic value in column 1\n",
    "   The second part[\"col2\"].describe() will summarize the datas in column 2, but only base on the subsets created previously \n",
    "based column 1. \n",
    "'''\n",
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "DEADvsNOTDEAD = df.groupby('survived')[\"age\"].describe()\n",
    "print(DEADvsNOTDEAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02b6521",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "df.describe() gives a single count for each column, based on non-missing values across the entire dataset.\n",
    "df.groupby(\"col1\")[\"col2\"].describe() gives a count for each unique group in col1, showing how many non-missing col2 values\n",
    "are present within each group.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41deb889",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nIntentially introducing errors to the code in order to get a response\\n\\n1. Forget to include import pandas as pd in your code\\n        Chatgpt provided valid solutions quickly and efficiently, it provided instructions on how to improve it and is \\n        easier to understand.\\n        \\n2. mistype 'titanic.csv'\\n        Chatgpt is still a more efficient tool in this case, base on my previous conversations with chatgpt, it located my\\n        errors quickly and provided me a solution that I can use.\\n        \\n3. Try to use a dataframe before it's been assigned into the variable\\n        Again, since chatgpt have the access to understand my actual code, it can locate the questions and return a answer \\n        back. However, using google search is extremely hard because how vague the error code is. \\n        \\n4. Forget one of the parentheses somewhere the code\\n        For this error, google search provided me a clear and correct answer to the error message. Chatgpt also responded,\\n        but instead of explaining the error, it tried to rewrite the code and created unnesscessary processes.\\n\\n5. Mistype one of the names of the chained functions with the code\\n        Chatgpt successfully identified my issue, took long to search in google searches\\n        \\n6. Use a column name that's not in your data for the groupby and column selection\\n        Chatgpt quickly identified the error and provide me an example about how to solve it. Where as it takes a while for\\n        me to find the desirable result from google search\\n        \\n7. Forget to put the column name as a string in quotes for the groupby and column selection\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Intentially introducing errors to the code in order to get a response\n",
    "\n",
    "1. Forget to include import pandas as pd in your code\n",
    "        Chatgpt provided valid solutions quickly and efficiently, it provided instructions on how to improve it and is \n",
    "        easier to understand.\n",
    "        \n",
    "2. mistype 'titanic.csv'\n",
    "        Chatgpt is still a more efficient tool in this case, base on my previous conversations with chatgpt, it located my\n",
    "        errors quickly and provided me a solution that I can use.\n",
    "        \n",
    "3. Try to use a dataframe before it's been assigned into the variable\n",
    "        Again, since chatgpt have the access to understand my actual code, it can locate the questions and return a answer \n",
    "        back. However, using google search is extremely hard because how vague the error code is. \n",
    "        \n",
    "4. Forget one of the parentheses somewhere the code\n",
    "        For this error, google search provided me a clear and correct answer to the error message. Chatgpt also responded,\n",
    "        but instead of explaining the error, it tried to rewrite the code and created unnesscessary processes.\n",
    "\n",
    "5. Mistype one of the names of the chained functions with the code\n",
    "        Chatgpt successfully identified my issue, took long to search in google searches\n",
    "        \n",
    "6. Use a column name that's not in your data for the groupby and column selection\n",
    "        Chatgpt quickly identified the error and provide me an example about how to solve it. Where as it takes a while for\n",
    "        me to find the desirable result from google search\n",
    "        \n",
    "7. Forget to put the column name as a string in quotes for the groupby and column selection\n",
    "        Chatgpt correctly recognized the issues after I spend in the entire error message. I struggled to find answer in\n",
    "        google search, because its too much to paste the entire error message, but to short for any useful info if I only\n",
    "        put the last line\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02b71690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Somewhat'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Somewhat'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cfab00",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
